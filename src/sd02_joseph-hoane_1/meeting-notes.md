## 3/26
- we need :
-          main.py to combine the arm and camera
-          simulated chess movement

## 3/11:
- There can be a 3 positions for the robot: high, low, and backup positions. 
- There will also be some space between the chess pieace and the board when the gripper is trying to put the piece on the bard for safety. 
- Also every 1-5 mins the gripper goes off so we have to start it again. 
- The gripper is Robotic hand E. We can also use more than 1 camera. 

## 2/24
- Discussed demo 1 and improved the materials of the slides
- Practiced the presentation

## 2/23
- Discussed the improvement of AprilTags detection
- Worked on the Image processing code
- Started on the demo 1 slides

## 2/22
- Discussed and worked on the board corners detection
- Discussed how socketfish works
- Printed a chess board and tried the AprilTags
- Helped teammates with Ubuntu installation

## 2/21
- The basic requirement for the 1st demo is having the chess engine to work
- Map the piece/board based on the april tags using the camera
- Covert the data to the 2D string
- Convert the 2D string to FEN string
- Input the FEN string to the chess engine
- The chess engine should be able to detect the move

## 2/7:
- Share a screenshot on how to setup the ur10e simulator
- Work is divided into a. Vision, b. Controls
- We can have our own chess piece
- As long as it runs on our laptop, it should be fine
- Next meeting: Tuesday
- Finalize work partitioning (currently, arm-controls: Nat, Shim, Autrin, Vision: Cal)
